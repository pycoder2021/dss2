{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434b256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Practical No-1\n",
    "\n",
    "#Program no 1\n",
    "\n",
    "Code:\n",
    "sister(X,Y):-\n",
    "X\\=Y,\n",
    "motherof(X,M),\n",
    "motherof(Y,M),\n",
    "female(Y).\n",
    "\n",
    "brother(X,Y):-\n",
    "X\\=Y,\n",
    "fatherof(X,Z),\n",
    "fatherof(Y,Z),\n",
    "male(Y).\n",
    "\n",
    "uncle(X,Y):-\n",
    "fatherof(X,Z),\n",
    "brother(Z,Y).\n",
    "\n",
    "sibling(X,Y):-\n",
    "x\\=Y,\n",
    "motherof(X,M),\n",
    "motherof(Y,M),\n",
    "(female(X);male(X);male(Y);female(Y)).\n",
    "\n",
    "output code: \n",
    "?-fatherof(jimmy,P).\n",
    "?-sister(lesh,maya).\n",
    "?-brother(ratan,jimmy).\n",
    "?-brother(noel,jimmy).\n",
    "?-brother(neville,jimmy).\n",
    "?-uncle(neville,ratan).\n",
    "?-sibling(ratan,jimmy).\n",
    "?-sibling(neville,lesh).\n",
    "?-sibling(neville,maya).\n",
    "\n",
    "#Program no 2\n",
    "#To display numbers from 1 to n\n",
    "display_numbers(1):-write(1),n1.\n",
    "display_numbers(N):-\n",
    "N>1,\n",
    "write(N),n1\n",
    "N1 is N - 1,\n",
    "display_numbers(N1).\n",
    "\n",
    "Output code: ?-display_numbers(10)\n",
    "\n",
    "#Program  No 3\n",
    "/* find sum of list elements*/\n",
    "findsum(L):-\n",
    "sum(L,S),\n",
    "write('Sum of Given List:\"),write(S).\n",
    "sum([],0).\n",
    "sum([X|Tail],S):-\n",
    "sum(Tail,Temp),\n",
    "S is Temp + X.\n",
    "\n",
    "Output code: ?-sum([1,2,3,4],Sum).\n",
    "\n",
    "\n",
    "#Program No 4\n",
    "digits_reverse(N,X):-\n",
    "reverse(N,X,0/0.\n",
    "reversed(0,R,R).\n",
    "reversed(N,X,R):-\n",
    "N > 0,\n",
    "N0 is N//10,\n",
    "R1 is R*10+(N mod 10),\n",
    "reversed(N0,X,R1).\n",
    "\n",
    "Output code: ?-reverse([11,12,13,14,15],List).\n",
    "\n",
    "\tPractical No-2\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "###########\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Salary_Data.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 1].values\n",
    "###########\n",
    "dataset.head()\n",
    "###########\n",
    " #Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)\n",
    "###########\n",
    "# Fitting Simple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "###########\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "###########\n",
    "# Visualising the Training set results\n",
    "plt.scatter(X_train, y_train, color = 'red')\n",
    "plt.plot(X_train, regressor.predict(X_train), color = 'blue')\n",
    "\n",
    "##########\n",
    "# Visualising the Test set results\n",
    "plt.scatter(X_test, y_test, color = 'red')\n",
    "plt.plot(X_train, regressor.predict(X_train), color = 'blue')\n",
    "plt.title('Salary vs Experience (Test set)')\n",
    "plt.xlabel('Years of Experience')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tPractical No-3\n",
    "# Importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Loading the restaurant tips dataset\n",
    "data = pd.read_csv(\"tips_dataset.csv\")\n",
    "###########\n",
    "data.head()\n",
    "###########\n",
    "data.info()\n",
    "###########\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "data['sex']=le.fit_transform(data['sex'])\n",
    "data['smoker']=le.fit_transform(data['smoker'])\n",
    "data['day']=le.fit_transform(data['day'])\n",
    "data['time']=le.fit_transform(data['time'])\n",
    "###########\n",
    "data.head()\n",
    "###########\n",
    "# Preprocessing the data\n",
    "X = data.drop([\"tip\"], axis=1).values\n",
    "y = data[\"tip\"].values\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "###########\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "###########\n",
    "# Creating instances of the LinearRegression, Ridge, Lasso, and ElasticNet models\n",
    "lr = LinearRegression()\n",
    "ridge = Ridge(alpha=1.0)\n",
    "lasso = Lasso(alpha=1.0)\n",
    "enet = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
    "###########\n",
    "# Fitting the models on the training data\n",
    "lr.fit(X_train, y_train)\n",
    "ridge.fit(X_train, y_train)\n",
    "lasso.fit(X_train, y_train)\n",
    "enet.fit(X_train, y_train)\n",
    "###########\n",
    "# Predicting the tip amounts for the testing data\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "y_pred_enet = enet.predict(X_test)\n",
    "###########\n",
    "# Calculating the r2_score for each model\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "r2_enet = r2_score(y_test, y_pred_enet)\n",
    "###########\n",
    "# Displaying the r2_score for each model\n",
    "print(\"Linear Regression r2_score: \", r2_lr)\n",
    "print(\"Ridge r2_score: \", r2_ridge)\n",
    "print(\"Lasso r2_score: \", r2_lasso)\n",
    "print(\"ElasticNet r2_score: \", r2_enet)\n",
    "###########\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tPractical No-4\n",
    "# Importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "###########\n",
    "# Loading the Social Network Ads data\n",
    "data = pd.read_csv(\"Social_Network_Ads.csv\")\n",
    "###########\n",
    "data.head()\n",
    "###########\n",
    "data.tail()\n",
    "###########\n",
    "# Preprocessing the data\n",
    "X = data.iloc[:, [2, 3]].values\n",
    "y = data.iloc[:, 4].values\n",
    "###########\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "###########\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "###########\n",
    "# Creating an instance of the LogisticRegression classifier\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "###########\n",
    "# Fitting the model on the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "###########\n",
    "# Predicting the classes for the testing data\n",
    "y_pred = logreg.predict(X_test)\n",
    "###########\n",
    "# Calculating the probability estimates for the testing data\n",
    "y_prob = logreg.predict_proba(X_test)[:, 1]\n",
    "###########\n",
    "# Calculating the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "###########\n",
    "# Calculating the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "###########\n",
    "# Calculating the log loss\n",
    "logloss = log_loss(y_test, y_prob)\n",
    "print(\"Log Loss: \", logloss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tPractical No-5\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, log_loss\n",
    "###########\n",
    "data = pd.read_csv(\"exams.csv\")\n",
    "###########\n",
    "data.head()\n",
    "###########\n",
    "data.info()\n",
    "###########\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "data['gender']=le.fit_transform(data['gender'])\n",
    "data['race/ethnicity']=le.fit_transform(data['race/ethnicity'])\n",
    "data['parental level of education']=le.fit_transform(data['parental level of education'])\n",
    "data['lunch']=le.fit_transform(data['lunch'])\n",
    "data['test preparation course']=le.fit_transform(data['test preparation course'])\n",
    "###########\n",
    "data.info()\n",
    "###########\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('test preparation course', axis=1), data['test preparation course'], test_size=0.2, random_state=42)\n",
    "###########\n",
    "# Train logistic regression model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "###########\n",
    "# Predict on testing set\n",
    "y_pred = lr.predict(X_test)\n",
    "###########\n",
    "# Evaluate model\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "log_loss = log_loss(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_mat)\n",
    "print('Accuracy:', accuracy)\n",
    "print('Log Loss:', log_loss)\n",
    "###########\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tPractical No-6\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "###########\n",
    "df=pd.read_csv(\"iris.csv\")\n",
    "###########\n",
    "df.head()\n",
    "###########\n",
    "from sklearn.datasets import load_iris \n",
    "iris = load_iris()\n",
    "###########\n",
    "iris.target_names\n",
    "###########\n",
    "#The Perceptron classifiert can only be used on binary classification problems, but the Iris dataset consists\n",
    "fo three different classes, i.e. ’setosa','versicolor’,'virginica’, corresponding to the labels 0, 1, and 2:\n",
    "We will merge the classes 'versicolor' and 'virginica' into one class. This means that only two classes are left #\n",
    "targets = (iris.target==0).astype(np.int8)\n",
    "print(targets)\n",
    "###########\n",
    "from sklearn.model_selection import train_test_split \n",
    "datasets = train_test_split(iris.data,targets, test_size=0.2)\n",
    "train_data, test_data, train_labels, test_labels = datasets\n",
    "###########\n",
    "from sklearn.linear_model import Perceptron \n",
    "p = Perceptron(random_state=42,\n",
    "max_iter=10, tol=0.001)\n",
    "p.fit(train_data, train_labels)\n",
    "###########\n",
    "import random\n",
    "sample = random.sample(range(len(train_data)), 10)\n",
    "for i in sample:\n",
    "    print(i, p.predict([train_data[i]]))\n",
    "###########\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(p.predict(train_data), train_labels))\n",
    "###########\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(p.predict(test_data), test_labels))\n",
    "###########\n",
    "\n",
    "# importing modules and packages import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error \n",
    "from sklearn import preprocessing\n",
    "###########\n",
    "print(df.head()) \n",
    "print(df.columns)\n",
    "###########\n",
    "df.drop('Species', inplace = True,axis=1) \n",
    "###########\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "###########\n",
    "# creating feature variables \n",
    "X = df.drop('Id',axis= 1)\n",
    "y = df['Id'] \n",
    "print(X) \n",
    "print(y)\n",
    "###########\n",
    "# creating train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=101)\n",
    "###########\n",
    "# creating a regression model\n",
    "model = LinearRegression()\n",
    "###########\n",
    "# fitting the model \n",
    "model.fit(X_train,y_train)\n",
    "###########\n",
    "# making predictions\n",
    "predictions = model.predict(X_test)\n",
    "###########\n",
    "# model evaluation \n",
    "print('mean_squared_error : ', mean_squared_error(y_test, predictions)) \n",
    "print('mean_absolute_error : ', mean_absolute_error(y_test, predictions))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tPractical No-7\n",
    "# Importing the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading the dataset\n",
    "data = pd.read_csv(\"PlayTennis.csv\")\n",
    "###########\n",
    "data.head()\n",
    "###########\n",
    "data.info()\n",
    "###########\n",
    "#Changing the Datatypes of all the columns from object to int\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "data['Outlook']=le.fit_transform(data['Outlook'])\n",
    "data['Temperature']=le.fit_transform(data['Temperature'])\n",
    "data['Humidity']=le.fit_transform(data['Humidity'])\n",
    "data['Wind']=le.fit_transform(data['Wind'])\n",
    "data['Play Tennis']=le.fit_transform(data['Play Tennis'])\n",
    "###########\n",
    "data.head()\n",
    "###########\n",
    "# Splitting the data into features and target\n",
    "X = data.drop(columns=['Play Tennis'])\n",
    "y = data['Play Tennis']\n",
    "###########\n",
    "# Creating an instance of the DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(criterion='entropy')\n",
    "###########\n",
    "# Fitting the model on the data\n",
    "dt.fit(X, y)\n",
    "###########\n",
    "# Plotting the decision tree\n",
    "plt.figure(figsize=(15, 8))\n",
    "plot_tree(dt, filled=True, feature_names=X.columns)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tPractical No-8\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, CategoricalNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "###########\n",
    "# load the disease dataset\n",
    "df = pd.read_csv('disease.csv')\n",
    "###########\n",
    "df.head()\n",
    "###########\n",
    "df.tail()\n",
    "###########\n",
    "df.info()\n",
    "###########\n",
    "#Changing the Datatypes of all the columns from object to int\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df['Sore Throat']=le.fit_transform(df['Sore Throat'])\n",
    "df['Fever']=le.fit_transform(df['Fever'])\n",
    "df['Swollen Glands']=le.fit_transform(df['Swollen Glands'])\n",
    "df['Congestion']=le.fit_transform(df['Congestion'])\n",
    "df['Headache']=le.fit_transform(df['Headache'])\n",
    "df['Diagnosis']=le.fit_transform(df['Diagnosis'])\n",
    "###########\n",
    "df.info()\n",
    "###########\n",
    "df.head(11)\n",
    "###########\n",
    "#setting the dimenions of the plot\n",
    "fig,ax=plt.subplots(figsize=(6,6))\n",
    "sns.countplot(x=df['Sore Throat'],data=df)\n",
    "plt.title(\"Category wise count of 'Sore Throat'\")\n",
    "plt.xlabel(\"category\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "###########\n",
    "fig,ax=plt.subplots(figsize=(6,6))\n",
    "sns.countplot(x=df['Fever'],data=df)\n",
    "plt.title(\"Category wise count of 'Fever'\")\n",
    "plt.xlabel(\"category\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "###########\n",
    "fig,ax=plt.subplots(figsize=(6,6))\n",
    "sns.countplot(x=df['Congestion'],data=df)\n",
    "plt.title(\"Category wise count of 'Congestion'\")\n",
    "plt.xlabel(\"category\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "###########\n",
    "fig,ax=plt.subplots(figsize=(6,6))\n",
    "sns.countplot(x=df['Headache'],data=df)\n",
    "plt.title(\"Category wise count of 'Headache'\")\n",
    "plt.xlabel(\"category\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "###########\n",
    "fig,ax=plt.subplots(figsize=(6,6))\n",
    "sns.countplot(x=df['Diagnosis'],data=df)\n",
    "plt.title(\"Category wise count of 'Diagnosis'\")\n",
    "plt.xlabel(\"category\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "###########\n",
    "X=df.drop('Diagnosis',axis=1)\n",
    "y=df['Diagnosis']\n",
    "###########\n",
    "#Training algorithm\n",
    "classifier=MultinomialNB()\n",
    "classifier.fit(X,y)\n",
    "###########\n",
    "#Training algorithm\n",
    "classifier=CategoricalNB()\n",
    "classifier.fit(X,y)\n",
    "###########\n",
    "#Training algorithm\n",
    "classifier=GaussianNB()\n",
    "classifier.fit(X,y)\n",
    "###########\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix,precision_score,recall_score,f1_score\n",
    "###########\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "###########\n",
    "classifier=MultinomialNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "print(\"confusion matrix\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision:\",precision_score(y_test,y_pred))\n",
    "print(\"Recall:\",recall_score(y_test,y_pred))\n",
    "print(\"F1 score:\",f1_score(y_test,y_pred))\n",
    "print(\"Classification report:]n\",classification_report(y_test,y_pred))\n",
    "###########\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "classifier=CategoricalNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "print(\"confusion matrix\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision:\",precision_score(y_test,y_pred))\n",
    "print(\"Recall:\",recall_score(y_test,y_pred))\n",
    "print(\"F1 score:\",f1_score(y_test,y_pred))\n",
    "print(\"Classification report:]n\",classification_report(y_test,y_pred))\n",
    "###########\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "classifier=GaussianNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "print(\"confusion matrix\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"Accuracy:\",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision:\",precision_score(y_test,y_pred))\n",
    "print(\"Recall:\",recall_score(y_test,y_pred))\n",
    "print(\"F1 score:\",f1_score(y_test,y_pred))\n",
    "print(\"Classification report:]n\",classification_report(y_test,y_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tPractical No-9\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "###########\n",
    "df=pd.read_csv('Mall_Customers.csv')\n",
    "###########\n",
    "df\n",
    "###########\n",
    "df.shape\n",
    "###########\n",
    "df.head()\n",
    "###########\n",
    "df.tail()\n",
    "###########\n",
    "df.info()\n",
    "###########\n",
    "df.isnull().sum()\n",
    "###########\n",
    "df = df.rename(columns={'Genre': 'Gender'})\n",
    "###########\n",
    "df.info()\n",
    "###########\n",
    "df.describe()\n",
    "###########\n",
    "colnames=list(df.columns[1:-1])\n",
    "###########\n",
    "X=df.CustomerID\n",
    "y=df.Age\n",
    "names=df.Gender\n",
    "X,y=shuffle(X,y,random_state=42)\n",
    "###########\n",
    "X=X.values.reshape(-1,1)\n",
    "y=y.values.reshape(-1,1)\n",
    "model=KMeans(n_clusters=3,random_state=42)\n",
    "df_kmeans=model.fit(X)\n",
    "###########\n",
    "df_kmeans.labels_\n",
    "###########\n",
    "df_kmeans.cluster_centers_\n",
    "###########\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler,normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "import scipy.cluster.hierarchy as shc\n",
    "###########\n",
    "#Using map function\n",
    "df['Gender']=df['Gender'].map({'Male':1,'Female':0})\n",
    "###########\n",
    "#Display modified dataframe\n",
    "print(\"Modified Dataframe:\\n\",df)\n",
    "###########\n",
    "#standardize data\n",
    "scaler=StandardScaler()\n",
    "scaled_df=scaler.fit_transform(df)\n",
    "###########\n",
    "#normalizing the dat\n",
    "normalized_df=normalize(scaled_df)\n",
    "###########\n",
    "#converting numpy array into a pandas dataframe\n",
    "normalized_df=pd.DataFrame(normalized_df)\n",
    "###########\n",
    "#reducing the dimensions of the data\n",
    "pca=PCA(n_components=2)\n",
    "X_principal=pca.fit_transform(normalized_df)\n",
    "X_principal=pd.DataFrame(X_principal)\n",
    "X_principal.columns=['P1','P2']\n",
    "X_principal.head(2)\n",
    "###########\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Visualising the data')\n",
    "Dendrogram=shc.dendrogram((shc.linkage(X_principal,method='ward')))\n",
    "###########\n",
    "silhouette_scores=[]\n",
    "for n_cluster in range(2,8):\n",
    "    silhouette_scores.append(\n",
    "silhouette_score(X_principal,AgglomerativeClustering(n_clusters=n_cluster).fit_predict(X_principal)))\n",
    "###########\n",
    "#Plotting a bar graph to compare the results\n",
    "k=[2,3,4,5,6,7]\n",
    "plt.bar(k,silhouette_scores)\n",
    "plt.xlabel('Number of clusters',fontsize=10)\n",
    "plt.ylabel('Silhouette Score',fontsize=10)\n",
    "plt.show()\n",
    "###########\n",
    "agg=AgglomerativeClustering(n_clusters=3)\n",
    "agg.fit(X_principal)\n",
    "###########\n",
    "#Visualizing the clustering\n",
    "plt.scatter(X_principal['P1'],X_principal['P2'],c=AgglomerativeClustering(n_clusters=3).fit_predict(X_principal),cmap=plt.cm.winter)\n",
    "plt.show()\n",
    "###########\n",
    "#display the elbow chart to detect number of clusters\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sclaed_df=StandardScaler().fit_transform(df)\n",
    "###########\n",
    "#initialize kmeans parameters\n",
    "kmeans_kwargs={\n",
    "    \"init\":\"random\",\n",
    "    \"n_init\":10,\n",
    "    \"random_state\":1\n",
    "}\n",
    "###########\n",
    "#create list to hold SSe values for each k\n",
    "sse=[]\n",
    "for k in range(1,11):\n",
    "    kmeans=KMeans(n_clusters=k,**kmeans_kwargs)\n",
    "    kmeans.fit(scaled_df)\n",
    "    sse.append(kmeans.inertia_)\n",
    "###########\n",
    "plt.plot(range(1,11),sse)\n",
    "plt.xticks(range(1,11))\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()\n",
    "###########\n",
    "kmeans=KMeans(init=\"random\",n_clusters=9,n_init=10,random_state=1)\n",
    "kmeans.fit(scaled_df)\n",
    "kmeans.labels_\n",
    "###########\n",
    "df['cluster']=kmeans.labels_\n",
    "###########\n",
    "print(df)\n",
    "###########\n",
    "km=KMeans()\n",
    "X=np.random.rand(100,2)\n",
    "km.fit(X)\n",
    "print(km.labels_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tPractical No-10\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "###########\n",
    "df=pd.read_csv(\"iris.csv\")\n",
    "df\n",
    "###########\n",
    "df.columns\n",
    "###########\n",
    "df.info()\n",
    "###########\n",
    "df.Species.unique()\n",
    "###########\n",
    "df.shape\n",
    "###########\n",
    "X=df.drop(['Id','Species'],axis=1)\n",
    "y=df.Species\n",
    "###########\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "###########\n",
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "svc=SVC(gamma=0.0001)\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred=svc.predict(X_test)\n",
    "###########\n",
    "from  sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accuracy=\",accuracy_score(y_test,y_pred))\n",
    "###########\n",
    "#Hyper parameter tuning\n",
    "param_grid={'C': [0.001,0.1,1],'kernel':['linear','poly','rbf']}\n",
    "###########\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid=GridSearchCV(svc,param_grid,refit=True,verbose=3)\n",
    "grid.fit(X_train,y_train)\n",
    "###########\n",
    "print('Best parameters:',grid.best_params_)\n",
    "print('Best estimators:',grid.best_estimator_)\n",
    "print('Best score',grid.best_score_)\n",
    "###########\n",
    "#Display confusion matrix using best estimator\n",
    "svc=SVC(C=0.8,gamma=0.0001,kernel='linear')\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred=svc.predict(X_test)\n",
    "###########\n",
    "from  sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Accuracy=\",accuracy_score(y_test,y_pred))\n",
    "###########\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "clf=SVC(random_state=0)\n",
    "clf.fit(X_train,y_train)\n",
    "predictions=clf.predict(X_test)\n",
    "cm=confusion_matrix(y_test,predictions,labels=clf.classes_)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
